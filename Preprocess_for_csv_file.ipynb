{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime,timedelta\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path=r''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=r''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class empty_df_exception(Exception):\n",
    "    pass\n",
    "class cat_to_num_exception(Exception):\n",
    "    pass\n",
    "class save_df_to_csv_exception(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. import file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_files(file_path):\n",
    "    try:\n",
    "        df=pd.read_csv(file_path,low_memory=False)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Return a list of Unnumerical Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_positions(list_of_elems, element):\n",
    "    index_pos_list = []\n",
    "    index_pos = 0\n",
    "    while True:\n",
    "        try:\n",
    "            # Search for item in list from indexPos to the end of list\n",
    "            index_pos = list_of_elems.index(element, index_pos)\n",
    "            # Add the index position in list\n",
    "            index_pos_list.append(index_pos)\n",
    "            index_pos += 1\n",
    "        except ValueError as e:\n",
    "            break\n",
    "    return index_pos_list\n",
    "\n",
    "def nunmericalize_df_and_return_list_of_unumerical_cols(df,column_index_of_timestamp=0):\n",
    "    names=df.columns.to_list()\n",
    "    if(len(names)==0):\n",
    "        raise empty_df_exception('The input dataframe is empty!')\n",
    "    unnumerical_cols=[]\n",
    "    for i,name in enumerate(names):\n",
    "        if(i!=column_index_of_timestamp):\n",
    "            try:\n",
    "                df[name]=df[name].astype(float)\n",
    "            except:\n",
    "                unnumerical_cols.append(name)\n",
    "    return unnumerical_cols\n",
    "\n",
    "## after the first step of numericalize every column in the dataframe, we now have two kinds of \n",
    "## missing values in the dataframe: (1) standard missing value:NaN, this will pass the first step\n",
    "## thus the column that contains NaN will not be included in the unnumerical cols. (2) non-standard\n",
    "## missing values: any non-numerical record that is not NaN shall be deemed as this type of missing\n",
    "## values. Any column that includes this kind of missing value will be included in the list of \n",
    "## unnumerical_cols, we will need to go through each row in these columns to see which row includes\n",
    "## this kind of missing value.\n",
    "def numericalize_df_and_return_list_of_unnumerical_points(df,unnumerical_cols,column_index_of_timestamp=0):\n",
    "    unnumerical_dict={}\n",
    "    \n",
    "    ################## check for non-standard missing points #######################\n",
    "    for names in unnumerical_cols:\n",
    "        for i in df.shape[0]:\n",
    "            if(type(df[name][i])!=np.float64):\n",
    "                try:\n",
    "                    df[name][i]=float(df[name][i])\n",
    "                except:\n",
    "                    if(name in unnumerical_dict):\n",
    "                        unnumerical_dict[name].append(i)\n",
    "                    else:\n",
    "                        unnumerical_dict[name]=[i]\n",
    "    ################## check for non-standard missing points #######################\n",
    "    \n",
    "    ################## check for standard missing points #######################\n",
    "    names=df.columns.to_list()\n",
    "    for col_name in names:\n",
    "        NaN_index_list=get_index_positions(df[col_name].isnull().to_list(),True)\n",
    "        if(len(NaN_index_list)!=0):\n",
    "            if(col_name in unnumerical_dict):\n",
    "                unnumerical_dict[col_name].extend(NaN_index_list)\n",
    "            else:\n",
    "                unnumerical_dict[col_name]=NaN_index_list\n",
    "    ################## check for standard missing points #######################\n",
    "    \n",
    "    for name in unnumerical_dict:\n",
    "        unnumerical_dict[name]=list(set(unnumerical_dict[name]))\n",
    "    return unnumerical_dict\n",
    "\n",
    "def numericalize_df(df,column_index_of_timestamp=0):\n",
    "    unnumerical_cols=nunmericalize_df_and_return_list_of_unumerical_cols(df,column_index_of_timestamp)\n",
    "    unnumerical_dict=numericalize_df_and_return_list_of_unnumerical_points(df,unnumerical_cols,column_index_of_timestamp)\n",
    "    return unnumerical_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 get details about unnumerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class unnumerical_detail_pod:\n",
    "    def __init__(row_number,unique_vals):\n",
    "        self.unnumerical_rows_number=row_number\n",
    "        self.unique_val_set=unique_vals\n",
    "\n",
    "def get_details_about_unnumerical_data(df,unnumerical_dict):\n",
    "    details={}\n",
    "    names=df.columns.to_list()\n",
    "    for name in unnumerical_dict:\n",
    "        name_index=names.index(name)\n",
    "        unnumerical_val_set=set(df.iloc[unnumerical_dict[name],name_index].to_list())\n",
    "        details[name]=unnumerical_detail_pod(len(unnumerical_dict[name]),unnumerical_val_set)\n",
    "    return details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Fill in missing points with a fixed value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Fill in missing points with an artificial data(moving windows etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Categorical to Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_numerical(df,categorical_column_index):\n",
    "    try:\n",
    "        cat_col_set=set(df.iloc[:,categorical_column_index].to_list())\n",
    "        counter=0.0\n",
    "        name_to_val={}\n",
    "        for name in cat_col_set:\n",
    "            name_to_val[name]=counter\n",
    "            counter+=1\n",
    "        for i in range(df.shape[0]):\n",
    "            df.iloc[i,categorical_column_index]=name_to_val[df.iloc[i,categorical_column_index]]\n",
    "    except Exception as e:\n",
    "        raise cat_to_num_exception(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Check if the timestamp column is continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_time_col_continuation(df,time_col_index,granularity_in_minutes,parse_time_format):\n",
    "    time_col=df.iloc[:,time_col_index]\n",
    "    previous=datetime.strptime(time_col[0],parse_time_format)\n",
    "    standard_time_interval=timedelta(minutes=granularity_in_minutes)\n",
    "    gap_timestamp_pairs={}\n",
    "    for i in range(1,df.shape[0]):\n",
    "        current=datetime.strptime(time_col[i],parse_time_format)\n",
    "        if(current-previous!=standard_time_interval):\n",
    "            gap_timestamp_pairs[(i-1,i)]=(previous,current)\n",
    "        previous=current\n",
    "    return gap_timestamp_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. z-score normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_normalization(df,time_col_index):\n",
    "    new_df=df.drop(df.columns[time_col_index],axis=1)\n",
    "    for col in new_df.columns:\n",
    "        mean=np.mean(new_df[col])\n",
    "        std=np.std(new_df[col])\n",
    "        new_df[col]=(new_df[col]-mean)/(std+1e-7) # in case, std==0\n",
    "    for col in new_df.columns:\n",
    "        df[col]=new_df[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 min_max_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalization(df,time_col_index):\n",
    "    new_df=df.drop(df.columns[time_col_index],axis=1)\n",
    "    for col in new_df.columns:\n",
    "        max_val=np.max(new_df[col])\n",
    "        min_val=np.min(new_df[col])\n",
    "        new_df[col]=(new_df[col]-min_val)/(max_val-min_val+1e-7) #in case max_val==min_val\n",
    "    for col in new_df.columns:\n",
    "        df[col]=new_df[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save preprocessed dataframe to a designated place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_to_csv(df,save_path):\n",
    "    try:\n",
    "        df.to_csv(save_path,index=False)\n",
    "    except Exception as e:\n",
    "        raise save_df_to_csv_exception(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of preprocessing has to be an interactive process since there is no general way of dealing with unnumerical record, user has to decide how they want to deal with the unnunmerical data and this will determine how the preprocess will proceed, this scipt shall provide (1) how to proceed with the preprocessing of a csv file (2) some solutions to different kinds of problems that could occur. However, it is always encouraged that the users inject more steps/methods into this scipt o customize their own preprocessing script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step one: get the df:\n",
    "df=import_files(os.path.join(folder_path,file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step two: numericalize and get unnumerical list:\n",
    "unnumericalize_dict=numericalize_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step three: get unnumerical details:\n",
    "unnumerical_details=get_details_about_unnumerical_data(df,unnumericalize_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "## step four: chekc unnumerical details:\n",
    "print(unnumerical_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step five: deal with unnumerical details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## step six: check continuation of timestamp column:\n",
    "check_time_col_continuation(df,0,10,'%Y/%m/%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step seven: normalization:\n",
    "z_score_normalization(df,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step seven: save file:\n",
    "save_path=r'D:\\past_repos\\AIOT_AD\\MSCRED\\preprocessed_data\\z_score_中山嘉明#6机汽机发电机.csv'\n",
    "save_df_to_csv(df,save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_TORCH",
   "language": "python",
   "name": "dl_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
